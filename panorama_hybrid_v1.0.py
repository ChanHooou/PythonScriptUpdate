import numpy as np
from PIL import Image
from pathlib import Path
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict, Set
import re
import cv2
from collections import defaultdict

@dataclass
class ImageMetadata:
    """ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°"""
    filename: str
    index: int
    front: int
    back: int
    right: int
    left: int
    
    @classmethod
    def parse_filename(cls, filename: str):
        pattern = r'p(\d+)[_\s]+f(\d+)[_\s]+b(\d+)[_\s]+r(\d+)[_\s]+l(\d+)'
        match = re.search(pattern, filename, re.IGNORECASE)
        if not match:
            raise ValueError(f"Invalid filename format: {filename}")
        
        idx, f, b, r, l = match.groups()
        return cls(
            filename=filename,
            index=int(idx),
            front=int(f),
            back=int(b),
            right=int(r),
            left=int(l)
        )


class GlobalOptimizationStitcher:
    """ì „ì—­ ìµœì í™” íŒŒë…¸ë¼ë§ˆ ìŠ¤í‹°ì¹­: ì„¼ì„œ ë°°ì¹˜ â†’ ì¸ì ‘ ì´ë¯¸ì§€ í”¼ì²˜ ì •í•©"""
    
    def __init__(self, 
                 folder_path: str, 
                 building_width: int = None, 
                 building_height: int = None,
                 image_real_width: int = None,
                 image_real_height: int = None,
                 sensor_mode: str = "BL",
                 movement_direction: str = "forward",
                 use_global_optimization: bool = True,
                 overlap_threshold: float = 0.3,
                 refinement_iterations: int = 3,
                 feature_method: str = "SIFT"):
        """
        Args:
            folder_path: ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
            building_width: ê±´ë¬¼ ê°€ë¡œ ê¸¸ì´ (cm)
            building_height: ê±´ë¬¼ ì„¸ë¡œ ê¸¸ì´ (cm)
            image_real_width: ì´ë¯¸ì§€ ì‹¤ì œ ê°€ë¡œ í¬ê¸° (cm)
            image_real_height: ì´ë¯¸ì§€ ì‹¤ì œ ì„¸ë¡œ í¬ê¸° (cm)
            sensor_mode: ì„¼ì„œ ì¡°í•© ("FL", "FR", "BL", "BR")
            movement_direction: ì´ë™ ë°©í–¥
            use_global_optimization: ì „ì—­ ìµœì í™” ì‚¬ìš© ì—¬ë¶€
            overlap_threshold: ê²¹ì¹¨ íŒë‹¨ ì„ê³„ê°’ (0.0~1.0)
            refinement_iterations: ì •ë°€í™” ë°˜ë³µ íšŸìˆ˜
            feature_method: í”¼ì²˜ ì¶”ì¶œ ë°©ë²• ("SIFT", "ORB")
        """
        self.folder_path = Path(folder_path)
        self.metadata_list: List[ImageMetadata] = []
        self.images: List[np.ndarray] = []
        self.building_width = building_width
        self.building_height = building_height
        
        self.sensor_mode = sensor_mode.upper()
        self.movement_direction = movement_direction.lower()
        
        if self.sensor_mode not in ["FL", "FR", "BL", "BR"]:
            raise ValueError(f"Invalid sensor_mode: {sensor_mode}")
        
        if self.movement_direction not in ["forward", "backward", "left", "right"]:
            raise ValueError(f"Invalid movement_direction: {movement_direction}")
        
        self.vertical_sensor = self.sensor_mode[0]
        self.horizontal_sensor = self.sensor_mode[1]
        
        self.use_global_optimization = use_global_optimization
        self.overlap_threshold = overlap_threshold
        self.refinement_iterations = refinement_iterations
        self.feature_method = feature_method.upper()
        
        self.IMAGE_REAL_WIDTH = image_real_width if image_real_width else 125
        self.IMAGE_REAL_HEIGHT = image_real_height if image_real_height else 87
        
        self.IMAGE_PIXEL_WIDTH = None
        self.IMAGE_PIXEL_HEIGHT = None
        
        self.CM_PER_PIXEL_X = None
        self.CM_PER_PIXEL_Y = None
        self.PIXEL_PER_CM_X = None
        self.PIXEL_PER_CM_Y = None
        
        # ì´ë¯¸ì§€ ìœ„ì¹˜ ì €ì¥ (ì „ì—­ ìµœì í™”ìš©)
        self.positions: List[Tuple[int, int]] = []
        
        # í”¼ì²˜ ë””í…í„°
        self.feature_detector = None
        self.feature_matcher = None
        if self.use_global_optimization:
            self._initialize_feature_detector()
        
        print(f"\n{'='*60}")
        print("Global Optimization Panorama Stitcher")
        print(f"{'='*60}")
        sensor_names = {"F": "Front", "B": "Back", "L": "Left", "R": "Right"}
        print(f"Sensor Mode: {self.sensor_mode} ({sensor_names[self.vertical_sensor]}/{sensor_names[self.horizontal_sensor]})")
        print(f"Movement Direction: {self.movement_direction}")
        if self.use_global_optimization:
            print(f"Global Optimization: Enabled")
            print(f"  Feature Method: {self.feature_method}")
            print(f"  Overlap Threshold: {self.overlap_threshold}")
            print(f"  Refinement Iterations: {self.refinement_iterations}")
        else:
            print(f"Global Optimization: Disabled (Sensor-only)")
        
    def _initialize_feature_detector(self):
        """í”¼ì²˜ ë””í…í„° ì´ˆê¸°í™”"""
        try:
            if self.feature_method == "SIFT":
                self.feature_detector = cv2.SIFT_create(nfeatures=2000)
                self.feature_matcher = cv2.FlannBasedMatcher(
                    dict(algorithm=1, trees=5),
                    dict(checks=50)
                )
            else:
                self.feature_detector = cv2.ORB_create(nfeatures=2000)
                self.feature_matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
            
            print(f"  âœ“ {self.feature_method} feature detector initialized")
                
        except Exception as e:
            print(f"  âš  Feature detector initialization failed: {e}")
            print(f"  Falling back to sensor-only mode")
            self.use_global_optimization = False
    
    def _calculate_scale(self):
        """ìŠ¤ì¼€ì¼ ê³„ì‚°"""
        if self.IMAGE_PIXEL_WIDTH and self.IMAGE_PIXEL_HEIGHT:
            self.CM_PER_PIXEL_X = self.IMAGE_REAL_WIDTH / self.IMAGE_PIXEL_WIDTH
            self.CM_PER_PIXEL_Y = self.IMAGE_REAL_HEIGHT / self.IMAGE_PIXEL_HEIGHT
            self.PIXEL_PER_CM_X = self.IMAGE_PIXEL_WIDTH / self.IMAGE_REAL_WIDTH
            self.PIXEL_PER_CM_Y = self.IMAGE_PIXEL_HEIGHT / self.IMAGE_REAL_HEIGHT
            
            print(f"Image size: {self.IMAGE_PIXEL_WIDTH} x {self.IMAGE_PIXEL_HEIGHT} px")
            print(f"Real size: {self.IMAGE_REAL_WIDTH} x {self.IMAGE_REAL_HEIGHT} cm")
            print(f"Scale: {self.PIXEL_PER_CM_X:.3f} px/cm (X), {self.PIXEL_PER_CM_Y:.3f} px/cm (Y)")
            print(f"{'='*60}")
    
    def _get_sort_key(self, meta: ImageMetadata):
        """ì •ë ¬ í‚¤ ë°˜í™˜"""
        if self.movement_direction == "forward":
            return -meta.front if self.vertical_sensor == "F" else meta.back
        elif self.movement_direction == "backward":
            return meta.front if self.vertical_sensor == "F" else -meta.back
        elif self.movement_direction == "left":
            return -meta.left if self.horizontal_sensor == "L" else meta.right
        elif self.movement_direction == "right":
            return meta.left if self.horizontal_sensor == "L" else -meta.right
    
    def load_images_from_folder(self):
        """í´ë”ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ"""
        image_files_set = set()
        for ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG', '*.png', '*.PNG']:
            image_files_set.update(self.folder_path.glob(ext))
        
        image_files = list(image_files_set)
        
        if not image_files:
            raise FileNotFoundError(f"No images found in {self.folder_path}")
        
        print(f"\nFound {len(image_files)} images")
        
        temp_data = []
        for img_path in image_files:
            try:
                meta = ImageMetadata.parse_filename(img_path.name)
                temp_data.append((meta, img_path))
            except ValueError as e:
                print(f"  âš  Skipping {img_path.name}: {e}")
        
        if len(temp_data) == 0:
            raise ValueError("No valid images found")
        
        temp_data.sort(key=lambda x: self._get_sort_key(x[0]))
        
        with Image.open(str(temp_data[0][1])) as first_img:
            self.IMAGE_PIXEL_WIDTH, self.IMAGE_PIXEL_HEIGHT = first_img.size
        
        self._calculate_scale()
        
        for idx, (meta, img_path) in enumerate(temp_data):
            self.metadata_list.append(meta)
            
            with Image.open(str(img_path)) as img:
                img_array = np.array(img)
            
            h, w = img_array.shape[:2]
            if h != self.IMAGE_PIXEL_HEIGHT or w != self.IMAGE_PIXEL_WIDTH:
                with Image.open(str(img_path)) as img:
                    img_resized = img.resize((self.IMAGE_PIXEL_WIDTH, self.IMAGE_PIXEL_HEIGHT), Image.LANCZOS)
                    img_array = np.array(img_resized)
            
            self.images.append(img_array)
            
            if idx < 5:
                print(f"  [{idx:03d}] F:{meta.front:05d} B:{meta.back:05d} R:{meta.right:05d} L:{meta.left:05d}")
        
        print(f"\nâœ“ Successfully loaded {len(self.images)} images")
    
    def calculate_sensor_offset(self, idx: int) -> Tuple[int, int]:
        """ì„¼ì„œ ê¸°ë°˜ ì˜¤í”„ì…‹ ê³„ì‚°"""
        if idx == 0:
            return (0, 0)
        
        prev = self.metadata_list[idx - 1]
        curr = self.metadata_list[idx]
        
        # ì„¸ë¡œì¶•(Y)
        if self.vertical_sensor == "F":
            front_diff = prev.front - curr.front
            dy = -int(front_diff * self.PIXEL_PER_CM_Y)
        else:
            back_diff = curr.back - prev.back
            dy = -int(back_diff * self.PIXEL_PER_CM_Y)
        
        # ê°€ë¡œì¶•(X)
        if self.horizontal_sensor == "L":
            left_diff = curr.left - prev.left
            dx = int(left_diff * self.PIXEL_PER_CM_X)
        else:
            right_diff = curr.right - prev.right
            dx = -int(right_diff * self.PIXEL_PER_CM_X)
        
        # ë¶€ ì´ë™ì¶• ì œí•œ
        if self.movement_direction in ["forward", "backward"]:
            max_dx = int(self.IMAGE_PIXEL_WIDTH * 0.15)
            dx = max(-max_dx, min(max_dx, dx))
        else:
            max_dy = int(self.IMAGE_PIXEL_HEIGHT * 0.15)
            dy = max(-max_dy, min(max_dy, dy))
        
        return (dx, dy)
    
    def build_initial_layout_sensor(self):
        """Phase 1: ì„¼ì„œ ë°ì´í„°ë¡œ ì´ˆê¸° ë°°ì¹˜ êµ¬ì¶•"""
        print(f"\n{'='*60}")
        print("Phase 1: Building Initial Layout from Sensor Data")
        print(f"{'='*60}")
        
        h = self.IMAGE_PIXEL_HEIGHT
        w = self.IMAGE_PIXEL_WIDTH
        
        self.positions = [(0, 0)]
        
        for i in range(1, len(self.images)):
            dx, dy = self.calculate_sensor_offset(i)
            prev_x, prev_y = self.positions[-1]
            new_x = prev_x + dx
            new_y = prev_y + dy
            self.positions.append((new_x, new_y))
            
            if i < 5 or i % 10 == 0:
                direction_v = "â†‘" if dy < 0 else "â†“" if dy > 0 else "â€”"
                direction_h = "â†" if dx < 0 else "â†’" if dx > 0 else ""
                print(f"Image {i:3d}: offset=({dx:+5d}, {dy:+5d}) {direction_h}{direction_v} â†’ pos=({new_x:6d}, {new_y:6d}) [sensor]")
        
        print(f"\nâœ“ Initial layout completed with {len(self.positions)} images")
    
    def _create_overlap_masks(self, shape1: Tuple[int, int], shape2: Tuple[int, int],
                              idx1: int, idx2: int) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """ì´ë™ ë°©í–¥ì— ë”°ë¼ ê²¹ì¹¨ ì˜ì—­ì— ëŒ€í•œ ë§ˆìŠ¤í¬ ìƒì„±

        Args:
            shape1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ shape (h, w)
            shape2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ shape (h, w)
            idx1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì¸ë±ìŠ¤
            idx2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ ì¸ë±ìŠ¤

        Returns:
            (mask1, mask2): ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë§ˆìŠ¤í¬ (Noneì´ë©´ ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©)
        """
        h1, w1 = shape1
        h2, w2 = shape2

        # ì´ë™ ë°©í–¥ì´ ì „ì§„/í›„ì§„ì¼ ë•Œë§Œ íŠ¹ìˆ˜ ì²˜ë¦¬
        if self.movement_direction not in ["forward", "backward"]:
            return None, None

        # ìœ„ì¹˜ ê´€ê³„ íŒŒì•…
        y1, y2 = self.positions[idx1][1], self.positions[idx2][1]

        # ê²¹ì¹¨ ì˜ì—­ ë¹„ìœ¨ (ì´ë¯¸ì§€ ë†’ì´ì˜ 50% - ì¶©ë¶„í•œ íŠ¹ì§•ì  í™•ë³´)
        overlap_ratio = 0.50
        overlap_height = int(h1 * overlap_ratio)

        mask1 = None
        mask2 = None

        if self.movement_direction == "forward":
            # Forward: ì•„ë˜ìª½ ì´ë¯¸ì§€ê°€ ìœ„ìª½ ì´ë¯¸ì§€ë³´ë‹¤ y ê°’ì´ ì‘ìŒ (ìœ„ë¡œ ì´ë™)
            if y2 < y1:  # idx2ê°€ idx1ë³´ë‹¤ ìœ„ì— ìˆìŒ
                # idx1ì˜ ìƒë‹¨ ì˜ì—­, idx2ì˜ í•˜ë‹¨ ì˜ì—­ ë§¤ì¹­
                mask1 = np.zeros((h1, w1), dtype=np.uint8)
                mask1[0:overlap_height, :] = 255

                mask2 = np.zeros((h2, w2), dtype=np.uint8)
                mask2[h2-overlap_height:h2, :] = 255
            else:  # idx2ê°€ idx1ë³´ë‹¤ ì•„ë˜ì— ìˆìŒ
                # idx1ì˜ í•˜ë‹¨ ì˜ì—­, idx2ì˜ ìƒë‹¨ ì˜ì—­ ë§¤ì¹­
                mask1 = np.zeros((h1, w1), dtype=np.uint8)
                mask1[h1-overlap_height:h1, :] = 255

                mask2 = np.zeros((h2, w2), dtype=np.uint8)
                mask2[0:overlap_height, :] = 255

        elif self.movement_direction == "backward":
            # Backward: ìœ„ìª½ ì´ë¯¸ì§€ê°€ ì•„ë˜ìª½ ì´ë¯¸ì§€ë³´ë‹¤ y ê°’ì´ í¬ìŒ (ì•„ë˜ë¡œ ì´ë™)
            if y2 > y1:  # idx2ê°€ idx1ë³´ë‹¤ ì•„ë˜ì— ìˆìŒ
                # idx1ì˜ í•˜ë‹¨ ì˜ì—­, idx2ì˜ ìƒë‹¨ ì˜ì—­ ë§¤ì¹­
                mask1 = np.zeros((h1, w1), dtype=np.uint8)
                mask1[h1-overlap_height:h1, :] = 255

                mask2 = np.zeros((h2, w2), dtype=np.uint8)
                mask2[0:overlap_height, :] = 255
            else:  # idx2ê°€ idx1ë³´ë‹¤ ìœ„ì— ìˆìŒ
                # idx1ì˜ ìƒë‹¨ ì˜ì—­, idx2ì˜ í•˜ë‹¨ ì˜ì—­ ë§¤ì¹­
                mask1 = np.zeros((h1, w1), dtype=np.uint8)
                mask1[0:overlap_height, :] = 255

                mask2 = np.zeros((h2, w2), dtype=np.uint8)
                mask2[h2-overlap_height:h2, :] = 255

        return mask1, mask2

    def find_overlapping_neighbors(self, idx: int, max_distance: int = None) -> List[int]:
        """Phase 2: íŠ¹ì • ì´ë¯¸ì§€ì™€ ê²¹ì¹˜ëŠ” ì¸ì ‘ ì´ë¯¸ì§€ë“¤ ì°¾ê¸°
        
        Args:
            idx: ëŒ€ìƒ ì´ë¯¸ì§€ ì¸ë±ìŠ¤
            max_distance: ìµœëŒ€ ê±°ë¦¬ (í”½ì…€), Noneì´ë©´ ìë™ ê³„ì‚°
            
        Returns:
            ê²¹ì¹˜ëŠ” ì´ë¯¸ì§€ë“¤ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        if max_distance is None:
            # ì´ë¯¸ì§€ í¬ê¸°ì˜ 1.5ë°° ì´ë‚´
            max_distance = int(max(self.IMAGE_PIXEL_WIDTH, self.IMAGE_PIXEL_HEIGHT) * 1.5)
        
        x, y = self.positions[idx]
        w = self.IMAGE_PIXEL_WIDTH
        h = self.IMAGE_PIXEL_HEIGHT
        
        neighbors = []
        
        for i in range(len(self.images)):
            if i == idx:
                continue
            
            xi, yi = self.positions[i]
            
            # ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬ í™•ì¸
            dx = abs(xi - x)
            dy = abs(yi - y)
            
            if dx < max_distance and dy < max_distance:
                # ì‹¤ì œ ê²¹ì¹¨ ê³„ì‚°
                overlap_x = max(0, min(x + w, xi + w) - max(x, xi))
                overlap_y = max(0, min(y + h, yi + h) - max(y, yi))
                
                if overlap_x > 0 and overlap_y > 0:
                    overlap_area = overlap_x * overlap_y
                    total_area = w * h
                    overlap_ratio = overlap_area / total_area
                    
                    if overlap_ratio >= self.overlap_threshold:
                        neighbors.append(i)
        
        return neighbors
    
    def match_features_between_images(self, idx1: int, idx2: int) -> Optional[Tuple[int, int]]:
        """ë‘ ì´ë¯¸ì§€ ê°„ í”¼ì²˜ ë§¤ì¹­ìœ¼ë¡œ ìƒëŒ€ ì˜¤í”„ì…‹ ê³„ì‚°

        Args:
            idx1: ê¸°ì¤€ ì´ë¯¸ì§€ ì¸ë±ìŠ¤
            idx2: ë¹„êµ ì´ë¯¸ì§€ ì¸ë±ìŠ¤

        Returns:
            (dx, dy): idx2ê°€ idx1 ëŒ€ë¹„ ì´ë™í•´ì•¼ í•  ì˜¤í”„ì…‹, ì‹¤íŒ¨ì‹œ None
        """
        if not self.use_global_optimization:
            return None

        try:
            img1 = self.images[idx1]
            img2 = self.images[idx2]

            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY) if len(img1.shape) == 3 else img1
            gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY) if len(img2.shape) == 3 else img2

            # ROI ì„¤ì •: ì´ë™ ë°©í–¥ì— ë”°ë¼ ê²¹ì¹˜ëŠ” ì˜ì—­ì— ì§‘ì¤‘
            mask1, mask2 = self._create_overlap_masks(gray1.shape, gray2.shape, idx1, idx2)

            # í”¼ì²˜ ê²€ì¶œ (ë§ˆìŠ¤í¬ ì ìš©)
            kp1, des1 = self.feature_detector.detectAndCompute(gray1, mask1)
            kp2, des2 = self.feature_detector.detectAndCompute(gray2, mask2)
            
            if des1 is None or des2 is None or len(kp1) < 10 or len(kp2) < 10:
                return None
            
            # ë§¤ì¹­
            if self.feature_method == "SIFT":
                matches = self.feature_matcher.knnMatch(des1, des2, k=2)
                good_matches = []
                for m_n in matches:
                    if len(m_n) == 2:
                        m, n = m_n
                        if m.distance < 0.7 * n.distance:
                            good_matches.append(m)
            else:
                matches = self.feature_matcher.knnMatch(des1, des2, k=2)
                good_matches = []
                for m_n in matches:
                    if len(m_n) == 2:
                        m, n = m_n
                        if m.distance < 0.75 * n.distance:
                            good_matches.append(m)
            
            if len(good_matches) < 10:
                return None
            
            # í˜„ì¬ ìœ„ì¹˜ ì°¨ì´ (ì„¼ì„œ ê¸°ë°˜)
            x1, y1 = self.positions[idx1]
            x2, y2 = self.positions[idx2]
            sensor_dx = x2 - x1
            sensor_dy = y2 - y1
            
            # ë§¤ì¹­ëœ ì ë“¤ì˜ ë³€ìœ„
            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches])
            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches])
            
            displacements = dst_pts - src_pts
            
            # ì„¼ì„œ ì˜ˆì¸¡ ì£¼ë³€ í•„í„°ë§
            search_radius = 100  # í”½ì…€
            
            # ì˜ˆìƒë˜ëŠ” í”¼ì²˜ ì´ë™: img1ì˜ ì ì´ img2ì—ì„œ ì–´ë””ì— ë‚˜íƒ€ë‚ ì§€
            # img2ëŠ” img1 ëŒ€ë¹„ (sensor_dx, sensor_dy) ë§Œí¼ ì´ë™
            # ë”°ë¼ì„œ img1ì˜ í”¼ì²˜ëŠ” img2ì—ì„œ (-sensor_dx, -sensor_dy) ë°©í–¥ìœ¼ë¡œ ë³´ì—¬ì•¼ í•¨
            expected_dx = -sensor_dx
            expected_dy = -sensor_dy
            
            valid_mask = (
                (np.abs(displacements[:, 0] - expected_dx) < search_radius) &
                (np.abs(displacements[:, 1] - expected_dy) < search_radius)
            )
            
            if np.sum(valid_mask) < 5:
                return None
            
            # ì¤‘ì•™ê°’ìœ¼ë¡œ ë¡œë²„ìŠ¤íŠ¸ ì¶”ì •
            dx_feature = int(np.median(displacements[valid_mask, 0]))
            dy_feature = int(np.median(displacements[valid_mask, 1]))
            
            # í”¼ì²˜ ë§¤ì¹­ ê²°ê³¼: img1ì˜ ì ì´ img2ì—ì„œ (dx_feature, dy_feature) ì´ë™
            # ì´ëŠ” img2ê°€ img1 ëŒ€ë¹„ (-dx_feature, -dy_feature) ìœ„ì¹˜ì— ìˆë‹¤ëŠ” ì˜ë¯¸
            correction_dx = -dx_feature - sensor_dx
            correction_dy = -dy_feature - sensor_dy
            
            return (correction_dx, correction_dy)
            
        except Exception as e:
            return None
    
    def refine_positions_global(self):
        """Phase 3: ì¸ì ‘ ì´ë¯¸ì§€ë“¤ê³¼ì˜ í”¼ì²˜ ë§¤ì¹­ìœ¼ë¡œ ìœ„ì¹˜ ì •ë°€í™”"""
        print(f"\n{'='*60}")
        print("Phase 2: Finding Overlapping Neighbors")
        print(f"{'='*60}")
        
        # ê° ì´ë¯¸ì§€ì˜ ì¸ì ‘ ì´ë¯¸ì§€ ì°¾ê¸°
        neighbor_map: Dict[int, List[int]] = {}
        total_pairs = 0
        
        for i in range(len(self.images)):
            neighbors = self.find_overlapping_neighbors(i)
            neighbor_map[i] = neighbors
            total_pairs += len(neighbors)
            
            if i < 5 or len(neighbors) > 0 and i % 10 == 0:
                print(f"Image {i:3d}: {len(neighbors)} neighbors {neighbors[:5]}{'...' if len(neighbors) > 5 else ''}")
        
        print(f"\nâœ“ Found {total_pairs} overlapping pairs")
        
        if total_pairs == 0:
            print("âš  No overlapping images found, skipping refinement")
            return
        
        print(f"\n{'='*60}")
        print(f"Phase 3: Refining Positions with Feature Matching")
        print(f"{'='*60}")
        
        # ë°˜ë³µì  ì •ë°€í™”
        for iteration in range(self.refinement_iterations):
            print(f"\nIteration {iteration + 1}/{self.refinement_iterations}")
            
            # ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë³´ì •ê°’ ìˆ˜ì§‘
            corrections: Dict[int, List[Tuple[int, int]]] = defaultdict(list)
            successful_matches = 0
            failed_matches = 0
            
            # ëª¨ë“  ì¸ì ‘ ìŒì— ëŒ€í•´ í”¼ì²˜ ë§¤ì¹­
            processed_pairs = set()
            
            for i in range(len(self.images)):
                if i % 10 == 0 or i < 5:
                    print(f"  Processing image {i}/{len(self.images)}...", end='\r')
                
                for j in neighbor_map[i]:
                    # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
                    pair = tuple(sorted([i, j]))
                    if pair in processed_pairs:
                        continue
                    processed_pairs.add(pair)
                    
                    # í”¼ì²˜ ë§¤ì¹­
                    correction = self.match_features_between_images(i, j)
                    
                    if correction is not None:
                        dx, dy = correction
                        # jë¥¼ ë³´ì •
                        corrections[j].append((dx, dy))
                        successful_matches += 1
                    else:
                        failed_matches += 1
            
            print(f"  Processing image {len(self.images)}/{len(self.images)}... Done")
            print(f"  Feature matching: {successful_matches} success, {failed_matches} failed")
            
            if successful_matches == 0:
                print("  No successful matches, stopping refinement")
                break
            
            # ë³´ì • ì ìš© (í‰ê· ê°’ ì‚¬ìš©)
            max_correction = 0
            corrected_count = 0
            
            for i, correction_list in corrections.items():
                if len(correction_list) > 0:
                    # ì¤‘ì•™ê°’ìœ¼ë¡œ ë¡œë²„ìŠ¤íŠ¸í•˜ê²Œ
                    dx_corrections = [c[0] for c in correction_list]
                    dy_corrections = [c[1] for c in correction_list]
                    
                    dx_median = int(np.median(dx_corrections))
                    dy_median = int(np.median(dy_corrections))
                    
                    # ë³´ì • ì ìš©
                    x, y = self.positions[i]
                    self.positions[i] = (x + dx_median, y + dy_median)
                    
                    correction_magnitude = np.sqrt(dx_median**2 + dy_median**2)
                    max_correction = max(max_correction, correction_magnitude)
                    corrected_count += 1
            
            print(f"  Applied corrections to {corrected_count} images")
            print(f"  Max correction: {max_correction:.1f} pixels")
            
            # ìˆ˜ë ´ íŒë‹¨
            if max_correction < 2.0:  # 2í”½ì…€ ì´í•˜ë©´ ìˆ˜ë ´
                print(f"  Converged (max correction < 2 pixels)")
                break
        
        print(f"\nâœ“ Position refinement completed")
    
    def create_panorama(self) -> np.ndarray:
        """íŒŒë…¸ë¼ë§ˆ ìƒì„±"""
        if len(self.images) == 0:
            raise ValueError("No images loaded")
        
        # Phase 1: ì„¼ì„œ ê¸°ë°˜ ì´ˆê¸° ë°°ì¹˜
        self.build_initial_layout_sensor()
        
        # Phase 2 & 3: ì „ì—­ ìµœì í™”
        if self.use_global_optimization:
            self.refine_positions_global()
        
        # ìº”ë²„ìŠ¤ ìƒì„±
        print(f"\n{'='*60}")
        print("Phase 4: Generating Final Panorama")
        print(f"{'='*60}")
        
        h = self.IMAGE_PIXEL_HEIGHT
        w = self.IMAGE_PIXEL_WIDTH
        
        min_x = min(pos[0] for pos in self.positions)
        max_x = max(pos[0] for pos in self.positions) + w
        min_y = min(pos[1] for pos in self.positions)
        max_y = max(pos[1] for pos in self.positions) + h
        
        canvas_w = max_x - min_x + 400
        canvas_h = max_y - min_y + 400
        
        print(f"Canvas size: {canvas_w} x {canvas_h}")
        
        canvas = np.zeros((canvas_h, canvas_w, 3), dtype=np.uint8)
        
        offset_x = -min_x + 200
        offset_y = -min_y + 200
        
        # ì´ë¯¸ì§€ ë°°ì¹˜
        for i, (x, y) in enumerate(self.positions):
            abs_x = x + offset_x
            abs_y = y + offset_y
            
            y1 = max(0, min(abs_y, canvas_h - h))
            x1 = max(0, min(abs_x, canvas_w - w))
            y2 = y1 + h
            x2 = x1 + w
            
            img_y1, img_y2 = 0, h
            img_x1, img_x2 = 0, w

            if y1 <= 0:
                img_y1 = -y1
                y1 = 0
            if x1 <= 0:
                img_x1 = -x1
                x1 = 0
            if y2 > canvas_h:
                img_y2 = h - (y2 - canvas_h)
                y2 = canvas_h
            if x2 > canvas_w:
                img_x2 = w - (x2 - canvas_w)
                x2 = canvas_w

            if y2 > y1 and x2 > x1:
                canvas[y1:y2, x1:x2] = self.images[i][img_y1:img_y2, img_x1:img_x2]
        
        canvas = self._crop_canvas(canvas)
        
        print(f"\nFinal panorama: {canvas.shape[1]} x {canvas.shape[0]} px")
        real_w = canvas.shape[1] * self.CM_PER_PIXEL_X
        real_h = canvas.shape[0] * self.CM_PER_PIXEL_Y
        print(f"Real size: {real_w:.1f} x {real_h:.1f} cm")
        
        return canvas
    
    def _crop_canvas(self, canvas: np.ndarray) -> np.ndarray:
        """ë¹ˆ ì˜ì—­ ì œê±°"""
        gray = canvas.mean(axis=2)
        rows = np.any(gray > 0, axis=1)
        cols = np.any(gray > 0, axis=0)
        
        if not np.any(rows) or not np.any(cols):
            return canvas
        
        y1, y2 = np.where(rows)[0][[0, -1]]
        x1, x2 = np.where(cols)[0][[0, -1]]
        
        return canvas[y1:y2+1, x1:x2+1]
    
    def calculate_coverage_range(self) -> Tuple[int, int, int, int]:
        """ì´¬ì˜ ë²”ìœ„ ê³„ì‚°"""
        if not self.building_width or not self.building_height:
            return None, None, None, None
        
        if self.vertical_sensor == "F":
            f_values = [meta.front for meta in self.metadata_list]
            y_min = self.building_height - max(f_values)
            y_max = self.building_height - min(f_values)
        else:
            b_values = [meta.back for meta in self.metadata_list]
            y_min = min(b_values)
            y_max = max(b_values)
        
        if self.horizontal_sensor == "L":
            l_values = [meta.left for meta in self.metadata_list]
            x_min = min(l_values)
            x_max = max(l_values)
        else:
            r_values = [meta.right for meta in self.metadata_list]
            x_min = self.building_width - max(r_values)
            x_max = self.building_width - min(r_values)
        
        return int(y_min), int(y_max), int(x_min), int(x_max)
    
    def save_panorama(self, panorama: np.ndarray, output_path: str):
        """íŒŒë…¸ë¼ë§ˆ ì €ì¥"""
        h, w = panorama.shape[:2]
        max_dimension = 65000
        
        input_folder_name = self.folder_path.name
        
        if self.building_width and self.building_height:
            y_min, y_max, x_min, x_max = self.calculate_coverage_range()
            
            if y_min is not None:
                print(f"\nğŸ“ Coverage Range (Building Coordinate):")
                print(f"   Y: {y_min} ~ {y_max} cm")
                print(f"   X: {x_min} ~ {x_max} cm")
                
                base_path = Path(output_path)
                mode_str = "global" if self.use_global_optimization else "sensor"
                sensor_str = self.sensor_mode.lower()
                direction_str = self.movement_direction
                new_filename = f"{input_folder_name}_{mode_str}_{sensor_str}_{direction_str}_Ymin{y_min}_Ymax{y_max}_Xmin{x_min}_Xmax{x_max}.jpg"
                output_path = str(base_path.parent / new_filename)
        else:
            base_path = Path(output_path)
            mode_str = "global" if self.use_global_optimization else "sensor"
            sensor_str = self.sensor_mode.lower()
            direction_str = self.movement_direction
            new_filename = f"{input_folder_name}_{mode_str}_{sensor_str}_{direction_str}.jpg"
            output_path = str(base_path.parent / new_filename)
        
        if w > max_dimension or h > max_dimension:
            print(f"\nâš  Image too large ({w}x{h}), resizing for JPG...")
            
            if w > h:
                new_w = max_dimension
                new_h = int(h * (max_dimension / w))
            else:
                new_h = max_dimension
                new_w = int(w * (max_dimension / h))
            
            img_pil = Image.fromarray(panorama)
            img_pil_resized = img_pil.resize((new_w, new_h), Image.LANCZOS)
            
            png_path = output_path.replace('.jpg', '_full.png')
            try:
                img_pil.save(png_path, compress_level=3)
                print(f"âœ“ Full size (PNG): {png_path}")
            except Exception as e:
                print(f"  Failed to save full size PNG: {e}")
            
            img_to_save = img_pil_resized
        else:
            img_to_save = Image.fromarray(panorama)
        
        try:
            img_to_save.save(output_path, quality=95)
            print(f"âœ“ Saved: {output_path}")
        except Exception as e:
            try:
                png_path = output_path.replace('.jpg', '.png')
                img_to_save.save(png_path, compress_level=6)
                print(f"âœ“ Saved (PNG): {png_path}")
            except Exception as e2:
                print(f"âŒ Failed to save image: {e2}")
    
    def process(self, output_dir: str = "./output"):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        self.load_images_from_folder()
        
        panorama = self.create_panorama()
        
        input_folder_name = self.folder_path.name
        mode_str = "global" if self.use_global_optimization else "sensor"
        sensor_str = self.sensor_mode.lower()
        direction_str = self.movement_direction
        output_filename = f"{input_folder_name}_{mode_str}_{sensor_str}_{direction_str}.jpg"
        self.save_panorama(panorama, str(output_path / output_filename))
        
        print(f"\n{'='*60}")
        print("âœ“ Panorama generation completed!")
        print(f"{'='*60}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python panorama_global.py <image_folder> [output_folder] [sensor_mode] [movement_direction] [use_global] [overlap_threshold] [iterations] [building_width] [building_height] [image_real_width] [image_real_height]")
        print("\nExample:")
        print("  # Global optimization (default)")
        print("  python panorama_global.py ./images")
        print("  python panorama_global.py ./images ./output BL forward 1 0.3 3")
        print("\n  # Sensor-only mode")
        print("  python panorama_global.py ./images ./output BL forward 0")
        print("\n  # With building size")
        print("  python panorama_global.py ./images ./output BL forward 1 0.3 3 1620 810 125 87")
        print("\nArguments:")
        print("  sensor_mode        : 'FL', 'FR', 'BL', 'BR' (default: BL)")
        print("  movement_direction : 'forward', 'backward', 'left', 'right' (default: forward)")
        print("  use_global         : 0 (sensor-only) or 1 (global optimization) (default: 1)")
        print("  overlap_threshold  : 0.0~1.0, ê²¹ì¹¨ íŒë‹¨ ì„ê³„ê°’ (default: 0.3)")
        print("  iterations         : 1~10, ì •ë°€í™” ë°˜ë³µ íšŸìˆ˜ (default: 3)")
        print("  building_width     : ê±´ë¬¼ ì „ì²´ ê°€ë¡œ(X) ê¸¸ì´ (cm)")
        print("  building_height    : ê±´ë¬¼ ì „ì²´ ì„¸ë¡œ(Y) ê¸¸ì´ (cm)")
        print("  image_real_width   : ì´ë¯¸ì§€ 1ì¥ì˜ ì‹¤ì œ ê°€ë¡œ í¬ê¸° (cm, default: 125)")
        print("  image_real_height  : ì´ë¯¸ì§€ 1ì¥ì˜ ì‹¤ì œ ì„¸ë¡œ í¬ê¸° (cm, default: 87)")
        print("\nGlobal Optimization:")
        print("  Phase 1: Build initial layout from sensor data")
        print("  Phase 2: Find overlapping neighbor images")
        print("  Phase 3: Refine positions with feature matching")
        print("  Phase 4: Generate final panorama")
        
        sys.exit(0)
    
    folder_path = sys.argv[1]
    output_folder = sys.argv[2] if len(sys.argv) > 2 else "./output"
    sensor_mode = sys.argv[3] if len(sys.argv) > 3 else "BL"
    movement_direction = sys.argv[4] if len(sys.argv) > 4 else "forward"
    use_global = int(sys.argv[5]) if len(sys.argv) > 5 else 1
    overlap_threshold = float(sys.argv[6]) if len(sys.argv) > 6 else 0.3
    iterations = int(sys.argv[7]) if len(sys.argv) > 7 else 3
    building_width = int(sys.argv[8]) if len(sys.argv) > 8 else None
    building_height = int(sys.argv[9]) if len(sys.argv) > 9 else None
    image_real_width = int(sys.argv[10]) if len(sys.argv) > 10 else None
    image_real_height = int(sys.argv[11]) if len(sys.argv) > 11 else None
    
    try:
        stitcher = GlobalOptimizationStitcher(
            folder_path, 
            building_width=building_width,
            building_height=building_height,
            image_real_width=image_real_width,
            image_real_height=image_real_height,
            sensor_mode=sensor_mode,
            movement_direction=movement_direction,
            use_global_optimization=bool(use_global),
            overlap_threshold=overlap_threshold,
            refinement_iterations=iterations
        )
        stitcher.process(output_dir=output_folder)
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()